{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are using PyTorch version  1.4.0\n",
      "you have 2 GPUs\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "import gym\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical, Normal\n",
    "\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from utils.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('you are using PyTorch version ',torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    print(\"you have\", torch.cuda.device_count(), \"GPUs\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(device)\n",
    "else:\n",
    "    use_cuda = False\n",
    "    print('no GPUs detected')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Adversarial Inverse Reinforcement Learning\n",
    "\n",
    "When you get a large number of inputs x in sequence, but cannot store every x, yet would like to update M and V which are the running mean and variance. `ZFilter`  incorporates the input into a running estimate of mean and variance, then \n",
    "returns the z-score of the input \n",
    "\n",
    "initialize\n",
    "$M_1 = x_i$\n",
    "$V_1 = 0$\n",
    "\n",
    "$M_t = M_{t-1} + \\frac{(x_t + M_{t-1})}{t}$\n",
    "\n",
    "$S_t = S_{t-1} + \\frac{(x_t – M_{t-1})(x_t – M_t)}{t}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space Box(24,) action space Box(4,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BipedalWalker-v3') #env = gym.make('Hopper-v2')\n",
    "env.seed(0)\n",
    "torch.manual_seed(0)\n",
    "print(\"state space\", env.observation_space, \"action space\", env.action_space)\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "running_state = ZFilter((num_inputs,), clip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(mu, std):\n",
    "    action = torch.normal(mu, std)\n",
    "    action = action.data.numpy()\n",
    "    return action\n",
    "\n",
    "def get_entropy(mu, std):\n",
    "    dist = Normal(mu, std)\n",
    "    entropy = dist.entropy().mean()\n",
    "    return entropy\n",
    "\n",
    "def log_prob_density(x, mu, std):\n",
    "    log_prob_density = -(x - mu).pow(2) / (2 * std.pow(2)) \\\n",
    "                     - 0.5 * math.log(2 * math.pi)\n",
    "    return log_prob_density.sum(1, keepdim=True)\n",
    "\n",
    "def get_reward(vdb, state, action):\n",
    "    state = torch.Tensor(state)\n",
    "    action = torch.Tensor(action)\n",
    "    state_action = torch.cat([state, action])\n",
    "    with torch.no_grad():\n",
    "        return -math.log(vdb(state_action)[0].item())\n",
    "\n",
    "def kl_divergence(mu, logvar):\n",
    "    kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1, dim=1)\n",
    "    return kl_div\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_outputs)\n",
    "        \n",
    "        self.fc3.weight.data.mul_(0.1)\n",
    "        self.fc3.bias.data.mul_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        mu = self.fc3(x)\n",
    "        logstd = torch.zeros_like(mu)\n",
    "        std = torch.exp(logstd)\n",
    "        return mu, std\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.fc3.weight.data.mul_(0.1)\n",
    "        self.fc3.bias.data.mul_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        v = self.fc3(x)\n",
    "        return v\n",
    "\n",
    "\n",
    "class VDB(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size, z_size):\n",
    "        super(VDB, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, z_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, z_size)\n",
    "        self.fc4 = nn.Linear(z_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.fc5.weight.data.mul_(0.1)\n",
    "        self.fc5.bias.data.mul_(0.0)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        h = torch.tanh(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(logvar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def discriminator(self, z):\n",
    "        h = torch.tanh(self.fc4(z))\n",
    "        return torch.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        prob = self.discriminator(z)\n",
    "        return prob, mu, logvar\n",
    "    \n",
    "def train_vdb(vdb, memory, vdb_optim, demonstrations, beta, \n",
    "              vdb_update_num, I_c, alpha_beta):\n",
    "    \n",
    "    memory = np.array(memory) \n",
    "    states = np.vstack(memory[:, 0]) \n",
    "    actions = list(memory[:, 1]) \n",
    "\n",
    "    states = torch.Tensor(states)\n",
    "    actions = torch.Tensor(actions)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    for _ in range(vdb_update_num):\n",
    "        \n",
    "        learner, l_mu, l_logvar = vdb(torch.cat([states, actions], dim=1))\n",
    "        demonstrations = torch.Tensor(demonstrations)\n",
    "        expert, e_mu, e_logvar = vdb(demonstrations)\n",
    "\n",
    "        l_kld = kl_divergence(l_mu, l_logvar)\n",
    "        l_kld = l_kld.mean()\n",
    "        \n",
    "        e_kld = kl_divergence(e_mu, e_logvar)\n",
    "        e_kld = e_kld.mean()\n",
    "        \n",
    "        kld = 0.5 * (l_kld + e_kld)\n",
    "        bottleneck_loss = kld - I_c\n",
    "\n",
    "        beta = max(0, beta + alpha_beta * bottleneck_loss)\n",
    "\n",
    "        vdb_loss = criterion(learner, torch.ones((states.shape[0], 1))) + \\\n",
    "                   criterion(expert, torch.zeros((demonstrations.shape[0], 1))) + \\\n",
    "                   beta * bottleneck_loss\n",
    "                \n",
    "        vdb_optim.zero_grad()\n",
    "        vdb_loss.backward(retain_graph=True)\n",
    "        vdb_optim.step()\n",
    "\n",
    "    expert_acc = ((vdb(demonstrations)[0] < 0.5).float()).mean()\n",
    "    learner_acc = ((vdb(torch.cat([states, actions], dim=1))[0] > 0.5).float()).mean()\n",
    "\n",
    "    return expert_acc, learner_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(num_inputs, num_actions, hidden_size=128)\n",
    "critic = Critic(num_inputs, hidden_size=128)\n",
    "vdb = VDB(num_inputs + num_actions, hidden_size=128, z_size=4)\n",
    "\n",
    "learning_rate = 3e-4\n",
    "l2_rate = 1e-3\n",
    "\n",
    "actor_optim = optim.Adam(actor.parameters(), lr=learning_rate)\n",
    "critic_optim = optim.Adam(critic.parameters(), lr=learning_rate, weight_decay=l2_rate) \n",
    "vdb_optim = optim.Adam(vdb.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstrations.shape (50000, 14)\n",
      "[[-0.48224705 -1.18786003  1.84605944  0.62223241 -0.39152268 -3.21709328\n",
      "   0.05523458 -0.0175782   0.14056332  0.08432692  0.01398241  2.57012254\n",
      "   2.16022653  1.25368368]\n",
      " [-0.48457226 -1.11279922  1.86942212  0.62266743 -0.38204572 -3.11900995\n",
      "  -0.0192135   0.62860545  0.72578217  0.08719617  0.25489085  2.5566931\n",
      "   2.40988924  1.14469644]]\n"
     ]
    }
   ],
   "source": [
    "# load demonstrations\n",
    "expert_demo, _ = pickle.load(open('expert_demo.p', \"rb\"))\n",
    "demonstrations = np.array(expert_demo)\n",
    "print(\"demonstrations.shape\", demonstrations.shape) # (50000, 14)\n",
    "print(demonstrations[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 0\n",
    "train_discrim_flag = True\n",
    "max_iter_num = 4\n",
    "total_sample_size = 512\n",
    "num_steps = 100\n",
    "\n",
    "for iter in range(max_iter_num):\n",
    "    actor.eval(), critic.eval()\n",
    "    memory = deque()\n",
    "    steps = 0\n",
    "    scores = []\n",
    "    \n",
    "    while steps < total_sample_size: \n",
    "        \n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "\n",
    "        state = running_state(state)\n",
    "\n",
    "        for _ in range(num_steps): \n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            mu, std = actor(torch.Tensor(state).unsqueeze(0))\n",
    "            action = get_action(mu, std)[0]\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            irl_reward = get_reward(vdb, state, action)\n",
    "\n",
    "            if done:\n",
    "                mask = 0\n",
    "            else:\n",
    "                mask = 1\n",
    "\n",
    "            memory.append([state, action, irl_reward, mask])\n",
    "\n",
    "            next_state = running_state(next_state)\n",
    "            state = next_state\n",
    "\n",
    "            score += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        episodes += 1\n",
    "        scores.append(score)\n",
    "        \n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 28])\n"
     ]
    }
   ],
   "source": [
    "memory = np.array(memory) \n",
    "states = np.vstack(memory[:, 0]) \n",
    "actions = list(memory[:, 1]) \n",
    "\n",
    "states = torch.Tensor(states)\n",
    "actions = torch.Tensor(actions)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "print(torch.cat([states, actions], dim=1).shape) # torch.Size([70, 28])\n",
    "learner, l_mu, l_logvar = vdb(torch.cat([states, actions], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, vdb_update_num, I_c, alpha_beta = 0, 3, 0.5, 1e-4 \n",
    "expert_acc, learner_acc = train_vdb(vdb, memory, vdb_optim, demonstrations, \n",
    "                                    beta, vdb_update_num, I_c, alpha_beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
